{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd \nimport cv2\nimport random\nimport os\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport keras \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras import layers, models, optimizers\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-15T02:34:42.76241Z","iopub.execute_input":"2021-11-15T02:34:42.762818Z","iopub.status.idle":"2021-11-15T02:34:45.196349Z","shell.execute_reply.started":"2021-11-15T02:34:42.762785Z","shell.execute_reply":"2021-11-15T02:34:45.195555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_dir = '../input/face-mask-detection-data/with_mask'\nno_mask_dir = '../input/face-mask-detection-data/without_mask'\nmask_img = [f'{mask_dir}/{i}' for i in os.listdir(mask_dir)]\nno_mask_img = [f'{no_mask_dir}/{i}' for i in os.listdir(no_mask_dir)]","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:35:03.560352Z","iopub.execute_input":"2021-11-15T02:35:03.560606Z","iopub.status.idle":"2021-11-15T02:35:03.570783Z","shell.execute_reply.started":"2021-11-15T02:35:03.560577Z","shell.execute_reply":"2021-11-15T02:35:03.569964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total number of images with mask: \" + str(len(mask_img)))\nprint(\"Total number of images without mask: \" + str(len(no_mask_img)))\nprint(\"Total images: \" + str(len(mask_img) + len(no_mask_img)))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:35:04.719343Z","iopub.execute_input":"2021-11-15T02:35:04.719873Z","iopub.status.idle":"2021-11-15T02:35:04.725922Z","shell.execute_reply.started":"2021-11-15T02:35:04.719835Z","shell.execute_reply":"2021-11-15T02:35:04.724746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_mask = mask_img[0:1499]\ntr_no_mask = no_mask_img[0:1499]\ntest_mask = mask_img[1500:]\ntest_no_mask = no_mask_img[1500:]\n","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:35:05.952351Z","iopub.execute_input":"2021-11-15T02:35:05.952936Z","iopub.status.idle":"2021-11-15T02:35:05.957603Z","shell.execute_reply.started":"2021-11-15T02:35:05.952897Z","shell.execute_reply":"2021-11-15T02:35:05.956575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img = tr_mask + tr_no_mask\ntest_img = test_mask + test_no_mask","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:35:12.306075Z","iopub.execute_input":"2021-11-15T02:35:12.306772Z","iopub.status.idle":"2021-11-15T02:35:12.311026Z","shell.execute_reply.started":"2021-11-15T02:35:12.306719Z","shell.execute_reply":"2021-11-15T02:35:12.310057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_imgs(imgs, width=150, height=150):\n    x = []\n    y = []\n    for i in imgs:\n        x.append(cv2.resize(cv2.imread(i, cv2.IMREAD_COLOR), (width, height), interpolation=cv2.INTER_CUBIC))\n        label = 1 if 'without' in i else 0\n        y.append(label)\n    return np.array(x), np.array(y)\n\ntr_x, tr_y = process_imgs(train_img)\ntest_x, test_y = process_imgs(test_img)\n\n# plot 5 images just to see the results of processing the images\nplt.figure(figsize=(20, 10))\ncols = 5\nfor i in range(cols):\n    plt.subplot(5 / cols+1, cols, i+1) #keras\n    plt.imshow(tr_x[i])","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:35:13.83252Z","iopub.execute_input":"2021-11-15T02:35:13.833059Z","iopub.status.idle":"2021-11-15T02:35:29.287618Z","shell.execute_reply.started":"2021-11-15T02:35:13.833021Z","shell.execute_reply":"2021-11-15T02:35:29.287015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_data = ImageDataGenerator(rescale=1/255,\n                            rotation_range=40,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.2,\n                            zoom_range=0.2,\n                            horizontal_flip=True)\n\ntr_gen = tr_data.flow(tr_x, tr_y, batch_size=32)\ntest_gen = tr_data.flow(test_x, test_y, batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:35:29.289007Z","iopub.execute_input":"2021-11-15T02:35:29.289433Z","iopub.status.idle":"2021-11-15T02:35:29.551589Z","shell.execute_reply.started":"2021-11-15T02:35:29.289396Z","shell.execute_reply":"2021-11-15T02:35:29.550825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BUILDING OUR FIRST MODEL (WITHOUT TRANSFER LEARNING)","metadata":{}},{"cell_type":"code","source":"model2 = models.Sequential()\nmodel2.add(Conv2D(64, (1, 1), input_shape = (150,150,3), activation='relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Conv2D(128, (1, 1), activation='relu'))\nmodel2.add(layers.Flatten())\nmodel2.add(layers.Dense(256, activation='relu'))\nmodel2.add(layers.Dense(2, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:12:48.514912Z","iopub.execute_input":"2021-11-15T02:12:48.515607Z","iopub.status.idle":"2021-11-15T02:12:50.901415Z","shell.execute_reply.started":"2021-11-15T02:12:48.51557Z","shell.execute_reply":"2021-11-15T02:12:50.900575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nepochs = 20\nmodel2.compile(loss='sparse_categorical_crossentropy',\n             optimizer='adam',\n             metrics=['acc'])\nhist2 = model2.fit(tr_gen, steps_per_epoch=tr_x.shape[0] // batch_size, epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:13:18.785208Z","iopub.execute_input":"2021-11-15T02:13:18.785468Z","iopub.status.idle":"2021-11-15T02:19:28.360287Z","shell.execute_reply.started":"2021-11-15T02:13:18.785438Z","shell.execute_reply":"2021-11-15T02:19:28.359487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results2 = model2.evaluate(test_gen, batch_size = 32)\nprint(\"Test loss and test accuracy: \", results2)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:23:01.175263Z","iopub.execute_input":"2021-11-15T02:23:01.175806Z","iopub.status.idle":"2021-11-15T02:23:06.588871Z","shell.execute_reply.started":"2021-11-15T02:23:01.175772Z","shell.execute_reply":"2021-11-15T02:23:06.58814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs2 = list(range(1, len(hist2.history['acc'])+1))\naccuracy2 = hist2.history['acc']\nloss2 = hist2.history['loss']\n\nplt.subplot(2,1,1)\nplt.plot(epochs2, accuracy2)\nplt.title(\"CNN for Accuracy and Loss (Mask vs No Mask)\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.subplot(2,1,2)\nplt.plot(epochs2, loss2)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:23:24.863357Z","iopub.execute_input":"2021-11-15T02:23:24.863807Z","iopub.status.idle":"2021-11-15T02:23:25.179764Z","shell.execute_reply.started":"2021-11-15T02:23:24.863768Z","shell.execute_reply":"2021-11-15T02:23:25.179062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TRANSFER LEARNING :)","metadata":{}},{"cell_type":"code","source":"\nbase=InceptionResNetV2(input_shape = (150,150,3) , weights = 'imagenet' , include_top = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:46:05.723192Z","iopub.execute_input":"2021-11-15T02:46:05.723808Z","iopub.status.idle":"2021-11-15T02:46:10.580593Z","shell.execute_reply.started":"2021-11-15T02:46:05.723767Z","shell.execute_reply":"2021-11-15T02:46:10.579867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3 = models.Sequential()\nmodel3.add(base)\nmodel3.add(layers.Flatten())\nmodel3.add(layers.Dense(256, activation='relu'))\nmodel3.add(layers.Dense(2, activation='softmax'))\nbase.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:46:13.424804Z","iopub.execute_input":"2021-11-15T02:46:13.425557Z","iopub.status.idle":"2021-11-15T02:46:14.805184Z","shell.execute_reply.started":"2021-11-15T02:46:13.425518Z","shell.execute_reply":"2021-11-15T02:46:14.804472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:46:17.156735Z","iopub.execute_input":"2021-11-15T02:46:17.157336Z","iopub.status.idle":"2021-11-15T02:46:17.237766Z","shell.execute_reply.started":"2021-11-15T02:46:17.157282Z","shell.execute_reply":"2021-11-15T02:46:17.23468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nepochs = 20\nmodel3.compile(loss='sparse_categorical_crossentropy',\n             optimizer='adam',\n             metrics=['acc'])\nhist3 = model3.fit(tr_gen, steps_per_epoch=tr_x.shape[0] // batch_size, epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:46:20.78477Z","iopub.execute_input":"2021-11-15T02:46:20.785033Z","iopub.status.idle":"2021-11-15T02:52:41.445894Z","shell.execute_reply.started":"2021-11-15T02:46:20.784985Z","shell.execute_reply":"2021-11-15T02:52:41.445186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results3 = model3.evaluate(test_gen, batch_size = 32)\nprint(\"Test loss and test accuracy: \", results3)","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:52:58.910353Z","iopub.execute_input":"2021-11-15T02:52:58.910613Z","iopub.status.idle":"2021-11-15T02:53:06.941588Z","shell.execute_reply.started":"2021-11-15T02:52:58.910583Z","shell.execute_reply":"2021-11-15T02:53:06.940878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs3 = list(range(1, len(hist3.history['acc'])+1))\naccuracy3 = hist3.history['acc']\nloss3 = hist3.history['loss']\n\n\nplt.subplot(2,1,1)\nplt.plot(epochs3, accuracy3)\nplt.title(\"ImageNet and our NN for Accuracy and Loss (Mask vs No Mask)\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.subplot(2,1,2)\nplt.plot(epochs3, loss3)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T02:53:11.178754Z","iopub.execute_input":"2021-11-15T02:53:11.179016Z","iopub.status.idle":"2021-11-15T02:53:11.477559Z","shell.execute_reply.started":"2021-11-15T02:53:11.178971Z","shell.execute_reply":"2021-11-15T02:53:11.476876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}